---
title: "TSAR Complete Workflow"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{TSAR Complete Workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# TSAR Workflow

Pipeline analysis from raw data reading to graphic visualization

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Load Package and other relevant packages

Install package using devtools. Usage of dplyr and ggplot2 along with TSAR package is recommended for enhanced analysis.

```{r}
library(devtools)
devtools::install_local("/Users/candygao/Desktop/TSAR_0.1.0.tar.gz")
library(TSAR)
library(dplyr)
library(ggplot2)
```

## 2. Load Data

Read data in .txt or .csv format. Use read.delim function to input tab delimited file; use read.csv to input comma separated files. Other formats of input are welcomed as long as data is stored in data frame structure as numeric type. Ensure excessive lines are removed. (e.g. skip = , nrows = ) Means to check these are view(), pre-opening data file in excel, or manually removing all excessive data before input reading. Package defaults variable names as "Well.Position", "Temperature", "Fluorescence", "Normalized". Consider renaming data frame before proceding to following step.

```{r}
raw_data <- read.csv(file = "/Users/candygao/Desktop/qpcrresult/experiment file/Vitamin_RawData_Thermal Shift_02_162.eds.csv", header = TRUE, nrows = 118176)
```

## 3. Data Pre-Processing

Select data of individual cell for pre-analysis screening. e.g. select well A1

```{r}
test <- raw_data %>%
  filter(Well.Position == "A01") # select data for one well by well ID

#section data by temperature to remove messy area
#test <- subset(test, test$Temperature>40 & test$Temperature <50) 
```

Run example analysis on one well to screen potential errors and enhancement of model.

```{r}
#normalize fluorescence reading into scale between 0 and 1
test <- normalize(test, fluo = 5, selected = c("Well.Position", "Temperature", "Fluorescence", "Normalized")) 
head(test)
gammodel <- model_gam(test, x = test$Temperature, y = test$Normalized)
test <- model_fit(test, model = gammodel) #, smoothed="Fluorescence")
```

Output analysis result using ggplot to view normalized data and fitted model. Determine is any noise need to be removed (i.e. subsetting by temperature range). Determine which model is the best (i.e. is currrent data already smoothed, does fitted model suit well.) Determine if tm-estimation is proper. \*current model assumes derivative estimation of tm value.

```{r}
tm_est(test)
view_model(test)
```

Screen all wells for curve shape on raw_data set and sift out corrupted data. This step is not required but may help remove data modeling errors.

```{r}
myApp <- weed_raw(raw_data, checkrange= c("A","C","1","12"))
#shiny::runApp(myApp)

t_data <- remove_raw(raw_data, 
                     removelist = c('C04','B04','C03','C10','B11','C11','C02',
                                    'C12','C01','B06','C07','C09','C08','B05',
                                    'B07','C06','B12','C05','B08','B02','B01',
                                    'B03','B09','B10'))

t_data <- remove_raw(t_data, removerange = c("D","H","1","12"))
screen(t_data)
```

## 4. 96-well Analysis Application

TSAR package excels in mass analysis by propagating identical protocols to all 96 wells.

```{r, echo = FALSE}
#smoothed = T infers current data is smoothed and no separate gam modeling is needed. If modeling needed, input argument as smoothed = F
x <- gam_analysis(t_data, smoothed = T, fluo = 5, selections = c("Well.Position", "Temperature", "Fluorescence", "Normalized"))
x <- na.omit(x)
```

## 5. Intermediate Data Output

Read analysis using read_tsar() function and view head and tail to ensure appropriate output was achieved. Data output can also be saved locally into .csv or .txt format using function wrtie_tsar. However, pipeline to downstream analysis does not require output to be locally saved.

```{r, echo = FALSE}
#look at only tm result by well
output <- read_tsar(x, code = 0)
head(output)
tail(output)

#write output data file
write_tsar(read_tsar(x, code = 2), name = "0923_tm_val", file = "csv")
```

## 6. Complete Dataset with Ligand and Protein Information

For downstream analysis, data need to be mapped towards specific ligand and compound. Use may input by default excel template included in the package or input as .txt or .csv table, specifying Ligand and Compound by Well ID. Data with coumpound and ligand labels can also be stored locally using the same mean as previous step. All data are kept despite blank input. In case removal is needed, call function na.omit().

```{r, echo = FALSE}
#join protein and ligand information 
norm_data <- join_well_info("/Users/candygao/Desktop/qpcrresult/experiment file/0203Well Information.xlsx", read_tsar(x, code = 2), type = "by_template")
norm_data <- na.omit(norm_data)
head(norm_data)
tail(norm_data)

write_tsar(norm_data, name = "vitamin_tm_val_norm", file = "csv")
```

## 7. Merge Data across Biological Replicates

Repeat step 2 through 6 on replicate data set. A five step function call will complete all analysis. If additional screening is desired, a two step call will run the interactive window to allow selection of

```{r}
raw_data_rep <- read.csv(file = "/Users/candygao/Desktop/qpcrresult/experiment file/Vitamin_RawData_Thermal Shift_02_168.eds.csv", header = TRUE, nrows = 118176)

#remove blank wells and weed out corrupted curves
raw_data_rep <- remove_raw(raw_data_rep, removerange = c("B","H","1","12"))
myApp <- weed_raw(raw_data_rep) 

#shiny::runApp(myApp)
raw_data_rep <- remove_raw(raw_data_rep, removelist = 'A12')
screen(raw_data_rep)


analysis_rep <- gam_analysis(raw_data_rep , smoothed = T)
output_rep <- read_tsar(analysis_rep, code = 2)
norm_data_rep <- join_well_info("/Users/candygao/Desktop/qpcrresult/experiment file/0203Well Information.xlsx", output_rep, type = "by_template")
norm_data_rep <- na.omit(norm_data_rep)

```

Merge data by content. All data are marked its source file name and experiment date.

```{r}
norm_data <- na.omit(norm_data)
norm_data_rep <- na.omit(norm_data_rep)
Bigdata <- merge_norm(norm_data, norm_data_rep, 
                      "Vitamin_RawData_Thermal Shift_02_162.eds.csv", 
                      "Vitamin_RawData_Thermal Shift_02_168.eds.csv", 
                      "20230203", "20230209")

```

## 8. Tm Estimation Shift Visualization

Use condition_IDs() and well_IDs() to select or remove condition to visualize. Visualize Tm estimation by compound or ligand type in the format of box graph.

```{r}
condition_IDs(Bigdata)
well_IDs(Bigdata)
conclusion <- Bigdata%>%
  filter(condition_ID != "NA_NA") %>%
  filter(condition_ID != "CA FL_Riboflavin")
TSA_boxplot(conclusion, color_by = "Protein", label_by = "Ligand", separate_legend = FALSE)
```

## 9. TSA Curve Visualization

Specify Control condition by assigning condition_ID to control. tsa_compare_plot generated multiple line graphs for comparison.

```{r}
control_ID <- "CA FL_DMSO"

tsa_compare_plot(conclusion,
                 y = "RFU",
                 control_condition = control_ID)
```

## 10. Data Correction

If data correction is needed, select by condition or well IDs to view curves and estimated Tm values. Assess the validity of analysis and edit with caution.
```{r Data Correction}
error <- conclusion %>% filter(condition_ID == 'CA FL_PyxINE HCl')
TSA_wells_plot(error, separate_legend = FALSE)
```
